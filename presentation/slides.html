<!DOCTYPE html>
<html>

<head>
  <title>Auto.gov: Optimal On-chain Governance for DeFi</title>
  <link rel="stylesheet" href="presentation.css" />
  <link rel="stylesheet" href="presentation-fonts.css" />
  <meta charset="utf-8" />
</head>

<body>
  <textarea id="source">

class: center, middle

# Auto.gov: Optimal On-chain Governance for DeFi


Daniel Perez, Jiahua Xu, and Benjamin Livshits

---

class: center, middle

# Background

---

# Protocols for Loanable Funds (PLF)

* Protocol that intermediates funds between users
* Unlike peer-to-peer lending, funds are pooled
* Requires users to deposit collateral

.text-center[
![Protocols for Loanable Funds overview](../assets/plf.png)
.caption[Protocols for Loanable Funds overview]
]

---

# PLF definitions

* *Market* A smart contract acting as the intermediary of loanable funds for a particular crypto-asset, where users supply and borrow funds.
* *Supply* Funds deposited to a market that can be loaned out to other users and used as collateral against depositors' own borrow positions.
* *Borrow* Funds loaned out to users of a market.
* *Collateral* Funds available to back a user's aggregate borrow positions.
* *Locked funds* Funds remaining in the PLF smart contracts, equal to the difference between supplied and borrowed funds.

---

# Agents in the system

* *Supplier* A user who deposits funds to a market.
* *Borrower* A user who borrows funds from a market. Since a borrow position must be collateralized by deposited funds, a borrower must also be a supplier.
* *Liquidator* A user who purchases a borrower's supply in a market when the borrower's collateral to borrow ratio falls below some threshold.

---

# PLF building blocks

* *Interest rate models* Some function(s) taking liquidity as an argument and returning an interest rate
* *Interest disbursement mechanism* Interest typically accrued per second and paid out per block. Often an interest bearing derivative token used.
* *Collateral* Deposit that can be sold off to recover the debt of a defaulted position
* *Liquidations* The process of selling a borrower's collateral to recover the debt value upon default
* *Governance mechanism* Decentralized governance typically achieved through an ERC-20 governance token, where token holders' votes are in proportion to their stake

---


# Deep reinforcement learning overview

* A type of machine learning where an agent learns to make decisions by performing actions in an environment and receiving feedback in the form of rewards.
* Combines the concepts of Reinforcement Learning with deep learning techniques.
* Uses deep neural networks as function approximators to represent the policy, value function, or model of the environment.

---

# Components of Deep Reinforcement Learning

* *Agent* The agent takes actions in the environment.
* *Environment* The environment is the world in which the agent operates and receives rewards for its actions.
* *State* The state represents the current condition of the environment.
* *Action* The action is taken by the agent in response to the state.
* *Reward* The reward is feedback received by the agent in response to its actions.

---

class: center, middle

# Empirical results

---

# AAVE governance forum discussion

.text-center[
![AAVE governance forum discussion](../assets/aave_desc_tbl.svg)
]

---

# Empirical states of AAVE

.center-block.full-width-img[
![Empirical states of AAVE](../assets/empirical-states.svg)
]

---

# Empirical correlation of state variables

.text-center[
![Empirical correlation of state variables](../assets/aave_corr.svg)
]

---


class: center, middle

# Modelling  framework

---

# Deep reinforcement q-learning architecture

.pull-left-50[
![RL architecture applied to DeFi environment](../assets/arc-rl-arc.drawio.svg)
.caption[RL architecture applied to DeFi environment]
]

.pull-right-50[
![RL training](../assets/arc-training.drawio.svg)
.caption[RL training]
]

---

# A simplified DeFi environment for training (1/2)

* Three PLF pools
      * WETH &ndash; the numeraire for the protocol
      * USDC &ndash; a USD-pegged stablecoin
      * TKN &ndash; an arbitrary token
* One adjustable risk parameter: collateral factor
* One aggregate market user

---

# A simplified DeFi environment for training (2/2)

Pre-programmed user behavior reactive to market condition

* Motivated to deposit when collateral factor is low (safer market) and supply interest rate is high compared to competing rate; withdraw when the opposite is true
* Motivated to borrow when collateral factor is high, liquidation and collateral factor change do not occur often, and borrow interest rate is low compared to competing rate; repay when the opposite is true 
* Other action constraints apply (e.g. must have sufficient collateral to borrow, must have sufficient balance to withdraw, etc.)

---

# DeFi environment for training

.center-block.width-50[
![Simplified DeFi environment](../assets/arc-protocol.drawio.svg)
]

---

# Preliminary training results

.pull-left-50[
![Final collaterals of each game](../assets/end-collaterals.jpg)
.caption[Final collaterals of each game]
]

.pull-right-50[
![Training scores of each game](../assets/training-scores.jpg)
.caption[Training scores of each game]
]

---

# Future direction

* Add more training dimensions, e.g. more users with different risk preferences, more assets, more risk parameters
* Add more training scenarios, e.g. different market conditions (varying price volatility and competing interest rates etc.), different user behaviors
* Applying more sophisticated ML techniques, e.g. multi-agent RL by allowing users to also be reinforcement learning agents

---

# Conclusion

* We developed a deep reinforcement q-learning framework for modelling the dynamics of a PLF market
* Framework can learn the optimal policy for a simplified DeFi environment, and adjust collateral factor automatically to optimize the protocol
* We are working on extending the framework to a more realistic DeFi environment
* Learning result suggests that the optimal policy is to have the collateral factor highest for least volatile asset, and lowest for most volatile asset
* Aligns with the current AAVE governance mechanism; but able to learn the optimal policy in a more efficient and automated way

---

# Bibliography

.medium[
* Werner, S. M., Perez, D., Gudgeon, L., Klages-Mundt, A., Harz, D., & Knottenbelt, W. J. (2022). SoK: Decentralized Finance (DeFi). http://arxiv.org/abs/2101.08778
* Xu, J., & Vadgama, N. (2021). From banks to DeFi: the evolution of the lending market. In N. Vadgama, J. Xu, & P. Tasca (Eds.), Enabling the Internet of Value: How Blockchain Connects Global Businesses. http://arxiv.org/abs/2104.00970
* Perez, D., Werner, S. M., Xu, J., & Livshits, B. (2021). Liquidations: DeFi on a Knife-edge. International Conference on Financial Cryptography and Data Security (FC), 457–476. https://doi.org/10.1007/978-3-662-64331-0_24
* Gudgeon, L., Werner, S., Perez, D., & Knottenbelt, W. J. (2020). DeFi Protocols for Loanable Funds: Interest Rates, Liquidity and Market Efficiency. The 2nd ACM Conference on Advances in Financial Technologies, 92–112. https://doi.org/10.1145/3419614.3423254
]

    </textarea>
  <script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
  <script>
    var slideshow = remark.create({
      ratio: "16:9",
    });
  </script>
</body>

</html>