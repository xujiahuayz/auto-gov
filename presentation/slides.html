<!DOCTYPE html>
<html>
  <head>
    <title>Auto.gov: Optimal On-chain Governance for DeFi</title>
    <link rel="stylesheet" href="presentation.css" />
    <link rel="stylesheet" href="presentation-fonts.css" />
    <meta charset="utf-8" />
  </head>

  <body>
    <textarea id="source">

class: center, middle

# Auto.gov: Optimal On-chain Governance for DeFi


Daniel Perez, Jiahua Xu, and Benjamin Livshits

---

class: center, middle

# Background

---

# Protocols for Loanable Funds (PLF)

* Protocol that intermediates funds between users
* Unlike peer-to-peer lending, funds are pooled
* Requires users to deposit collateral

.text-center[
![Protocols for Loanable Funds overview](../assets/plf.png)
.caption[Protocols for Loanable Funds overview]
]

---

# PLF definitions

* *Market* A smart contract acting as the intermediary of loanable funds for a particular crypto-asset, where users supply and borrow funds.
* *Supply* Funds deposited to a market that can be loaned out to other users and used as collateral against depositors' own borrow positions.
* *Borrow* Funds loaned out to users of a market.
* *Collateral* Funds available to back a user's aggregate borrow positions.
* *Locked funds* Funds remaining in the PLF smart contracts, equal to the difference between supplied and borrowed funds.

---

# Agents in the system

* *Supplier* A user who deposits funds to a market.
* *Borrower* A user who borrows funds from a market. Since a borrow position must be collateralized by deposited funds, a borrower must also be a supplier.
* *Liquidator* A user who purchases a borrower's supply in a market when the borrower's collateral to borrow ratio falls below some threshold.

---

# PLF building blocks

* *Interest rate models*: Some function(s) taking liquidity as an argument and returning an interest rate
* *Interest disbursement mechanism*: Interest typically accrued per second and paid out per block. Often an interest bearing derivative token used.
* *Collateral*: Deposit that can be sold off to recover the debt of a defaulted position
* *Liquidations*: The process of selling a borrower's collateral to recover the debt value upon default
* *Governance mechanism*: Decentralized governance typically achieved through an ERC-20 governance token, where token holders' votes are in proportion to their stake

---


# Deep reinforcement learning overview

* A type of machine learning where an agent learns to make decisions by performing actions in an environment and receiving feedback in the form of rewards.
* Combines the concepts of Reinforcement Learning with deep learning techniques.
* Uses deep neural networks as function approximators to represent the policy, value function, or model of the environment.

---

# Components of Deep Reinforcement Learning

* *Agent*: The agent takes actions in the environment.
* *Environment*: The environment is the world in which the agent operates and receives rewards for its actions.
* *State*: The state represents the current condition of the environment.
* *Action*: The action is taken by the agent in response to the state.
* *Reward*: The reward is feedback received by the agent in response to its actions.

---

class: center, middle

.text-center[
![AAVE governance forum discussion](../assets/aave_desc_tbl.svg)
.caption[AAVE governance forum discussion]
]

---

.text-center[
![Empirical states of AAVE](../assets/empirical-states.svg)
.caption[Empirical states of AAVE]
]

---

.text-center[
![Empirical correlation of state variables](../assets/aave_corr.svg)
.caption[Empirical correlation of state variables]
]


---

# Modelling framework

## The deep reinforcement q-learning architecture

.pull-left-50[
![RL architecture applied to DeFi environment](../assets/arc-rl-arc.drawio.svg)
.caption[RL architecture applied to DeFi environment]
]

.pull-right-50[
![RL training](../assets/arc-training.drawio.svg)
.caption[RL training]
]

---

# A simplified DeFi environment for training (1/2)

* Three PLF pools
      * WETH &ndash; the numeraire for the protocol
      * USDC &ndash; a USD-pegged stablecoin
      * TKN &ndash; an arbitrary token
* One adjustable risk parameter: collateral factor
* One aggregate market user

---

# A simplified DeFi environment for training (2/2)

Pre-programmed user behavior reactive to market condition

* Motivated to deposit when collateral factor is low (safer market) and supply interest rate is high compared to competing rate; withdraw when the opposite is true
* Motivated to borrow when collateral factor is high, liquidation and collateral factor change do not occur often, and borrow interest rate is low compared to competing rate; repay when the opposite is true 
* Other action constraints apply (e.g. must have sufficient collateral to borrow, must have sufficient balance to withdraw, etc.)

---

# DeFi environment for training

.center-block.width-50[
![Simplified DeFi environment](../assets/arc-protocol.drawio.svg)
]

---

# Preliminary training results

.pull-left-50[
![Final collaterals of each game](../assets/end-collaterals.jpg)
.caption[Final collaterals of each game]
]

.pull-right-50[
![Training scores of each game](../assets/training-scores.jpg)
.caption[Training scores of each game]
]

---

## Preliminary results

## Future direction

## Conclusion

* We have developed a deep reinforcement q-learning framework for modelling the dynamics of a PLF market
* The framework is able to learn the optimal policy for a simplified DeFi environment, and adjust collateral factor automatically to optimize the protocol
* We are currently working on extending the framework to a more realistic DeFi environment
* The learning result suggests that the optimal policy is to have the collateral factor highest for the least volatile asset, and lowest for the most volatile asset -- which is intuitive
* The result in general aligns with the current AAVE governance mechanism; however, the framework is able to learn the optimal policy in a more efficient and automated way

---

## Bibliography

    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
    <script>
      var slideshow = remark.create({
        ratio: "16:9",
      });
    </script>
  </body>
</html>
